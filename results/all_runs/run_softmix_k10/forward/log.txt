{
  "experiment": {
    "mask_type": "soft",
    "topk_neighbors": 10,
    "mutual": true,
    "soft_mask": true,
    "mask_hub_tokens": false,
    "weights": "/workspace/toddler/vggt/model_tracker_fixed_e20.pt"
  },
  "runtime_s": 2.5150206089019775,
  "peak_VRAM_GB": 17.142675399780273,
  "runtime_source": "forward",
  "flex_attention_available": true,
  "torch_version": "2.6.0+cu124",
  "pose_AUC": null,
  "depth_RMSE": null,
  "sparsity": {
    "S": 25,
    "P": 930,
    "N": 23250,
    "hubs_per_frame": 5,
    "nonhub_per_frame": 925,
    "total_pairs": 540562500,
    "allowed_pairs": 211900500,
    "sparsity": 0.392,
    "adj_density": 0.3919999897480011,
    "mask_type": "soft",
    "topk_neighbors": 10,
    "mutual": true,
    "soft_mask": true,
    "mask_hub_tokens": false,
    "used_flex_attention": false,
    "used_sparse_context": true,
    "fallback_reason": "gate_use_flex_false"
  },
  "telemetry": {
    "used_flex_attention": false,
    "used_sparse_context": true,
    "entered_sparse": true,
    "adj_is_none": false,
    "soft_mask": true,
    "mask_hub_tokens": false,
    "q_len_init": 23250,
    "flex_import_ok": true,
    "fallback_reason": "gate_use_flex_false",
    "took_fallback_chunked": true
  }
}
